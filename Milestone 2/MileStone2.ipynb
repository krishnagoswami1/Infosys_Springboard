{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### 1. Setting Up the Environment\n\nThis first cell handles all the necessary setup. It installs the required Python libraries for running the language models (`transformers`, `torch`, `bitsandbytes`), data manipulation (`pandas`), and code analysis (`radon`). After installation, it imports all the modules that will be used throughout the notebook.","metadata":{}},{"cell_type":"code","source":"# --- Section 1: Setup & Installations ---\nprint(\"Installing required libraries...\")\n# Install all necessary packages quietly (-qqq flag)\n!pip install transformers torch accelerate bitsandbytes pandas huggingface_hub radon ipywidgets matplotlib seaborn -qqq -qqq > /dev/null 2>&1\n\n# Import necessary modules\nimport ipywidgets as widgets\nfrom IPython.display import display, HTML\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom huggingface_hub import notebook_login\nimport ast # Abstract Syntax Trees, used to check for valid Python code\nimport re # Regular expressions for cleaning text\nimport time\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom radon.complexity import cc_visit # For Cyclomatic Complexity\nfrom radon.metrics import mi_visit # For Maintainability Index\nfrom radon.raw import analyze # For Lines of Code (LOC)\nimport warnings\nwarnings.filterwarnings('ignore')\nprint(\"\\nSetup Complete! âœ…\")","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"execution":{"iopub.status.busy":"2025-10-16T18:06:43.559762Z","iopub.execute_input":"2025-10-16T18:06:43.560223Z","iopub.status.idle":"2025-10-16T18:08:13.192780Z","shell.execute_reply.started":"2025-10-16T18:06:43.560200Z","shell.execute_reply":"2025-10-16T18:08:13.191887Z"}},"outputs":[{"name":"stdout","text":"Installing required libraries...\n\nSetup Complete! âœ…\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### 2. Hugging Face Authentication\n\nTo download the pre-trained models from the Hugging Face Hub, we need to authenticate. This section retrieves a secret key (stored securely in Kaggle Secrets) and uses it to log in. This step is crucial for accessing gated models or private repositories.","metadata":{}},{"cell_type":"code","source":"# Import the secret client to access stored secrets\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\n# Retrieve the Hugging Face API key\nsecret_value = user_secrets.get_secret(\"HUGGINGFACE_KEY\")\n\n# Print a confirmation message without exposing the full key\nprint(secret_value[:5]+'*************************')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T18:08:13.194283Z","iopub.execute_input":"2025-10-16T18:08:13.194773Z","iopub.status.idle":"2025-10-16T18:08:13.298340Z","shell.execute_reply.started":"2025-10-16T18:08:13.194753Z","shell.execute_reply":"2025-10-16T18:08:13.297593Z"}},"outputs":[{"name":"stdout","text":"hf_WW*************************\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Use the retrieved key to log into the Hugging Face Hub\nfrom huggingface_hub import login\nlogin(token = secret_value)\nprint(\"Huggingface Login successful\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T18:08:13.299158Z","iopub.execute_input":"2025-10-16T18:08:13.299789Z","iopub.status.idle":"2025-10-16T18:08:13.486697Z","shell.execute_reply.started":"2025-10-16T18:08:13.299761Z","shell.execute_reply":"2025-10-16T18:08:13.485957Z"}},"outputs":[{"name":"stdout","text":"Huggingface Login successful\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### 3. Core Engine: Generation and Metrics\n\nThis cell contains the backbone of our analysis tool. It defines:\n1.  **Models to Test**: A dictionary mapping user-friendly names to their Hugging Face model paths.\n2.  **Helper Functions**:\n    * `clean_generated_code`: Each model has a unique way of formatting its output (e.g., special tokens, instructions). This function uses regular expressions to strip away the noise and extract only the raw Python code.\n    * `is_syntactically_valid`: Checks if the generated code can be parsed, ensuring it's valid Python syntax before we try to analyze it.\n    * `calculate_advanced_metrics`: Uses the `radon` library to compute key software metrics: Cyclomatic Complexity (decision complexity), Maintainability Index (ease of maintenance), and Lines of Code.\n    * `generate_code`: The main generation function. It formats the prompt for the specific model, generates code, measures the generation time, and then cleans the output.","metadata":{}},{"cell_type":"code","source":"\n\n# --- Model Configuration ---\n\n# Dictionary mapping friendly names to Hugging Face model identifiers\nMODELS_TO_TEST = {\n    \"DeepSeek-Coder-1.3B\": \"deepseek-ai/deepseek-coder-1.3b-instruct\",\n    \"Phi-2-2.7B\": \"microsoft/phi-2\",\n    \"Gemma-2B-IT\": \"google/gemma-2b-it\",\n    \"Stable-code-3b\": \"stabilityai/stable-code-3b\"\n}\n# Set the computation device to GPU (cuda) if available, otherwise CPU\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# --- Helper & Generation Functions ---\ndef clean_generated_code(text, model_path):\n    \"\"\"Cleans the raw model output to extract only the Python code.\"\"\"\n    model_path = model_path.lower()\n    # Model-specific cleaning logic\n    if \"gemma\" in model_path:\n        text = re.sub(r\"<start_of_turn>user\\n.*<end_of_turn>\\n<start_of_turn>model\\n\", \"\", text, flags=re.DOTALL).replace(\"<end_of_turn>\", \"\")\n    elif \"phi-2\" in model_path:\n        text = re.sub(r\"Instruct:.*\\nOutput:\", \"\", text, flags=re.DOTALL)\n        text = text.replace(\"<|endoftext|>\", \"\")\n    elif \"stable\" in model_path:\n        text = re.sub(r'\"\"\".*?\"\"\"\\s*', \"\", text, flags=re.DOTALL) # Remove docstrings\n        match = re.search(r\"```(?:python)?\\n(.*?)\\n```\", text, re.DOTALL) # Extract from markdown block\n        if match:\n            text = match.group(1)\n        text = re.sub(r\"<\\|?endoftext\\|?>\", \"\", text, flags=re.IGNORECASE)\n    else: # Default cleaning for instruction-tuned models\n        text = re.sub(r\"### Instruction:\\n.*\\n\\n### Response:\", \"\", text, flags=re.DOTALL)\n    \n    # General cleaning for code within markdown blocks\n    match = re.search(r\"```python\\n(.*?)\\n```\", text, re.DOTALL)\n    if match: text = match.group(1)\n    return text.strip()\n\ndef is_syntactically_valid(code_string: str) -> bool:\n    \"\"\"Checks if a string contains valid Python code using AST parsing.\"\"\"\n    if not code_string: return False\n    try:\n        ast.parse(code_string)\n        return True\n    except SyntaxError:\n        return False\n\ndef calculate_advanced_metrics(code_string):\n    \"\"\"Calculates code quality metrics if the code is syntactically valid.\"\"\"\n    if not is_syntactically_valid(code_string):\n        return {\"complexity\": None, \"maintainability\": None, \"loc\": None}\n    try:\n        # Calculate Cyclomatic Complexity, Maintainability Index, and Lines of Code\n        complexity = sum([c.complexity for c in cc_visit(code_string)]) if cc_visit(code_string) else 0\n        maintainability = mi_visit(code_string, multi=True)\n        loc = analyze(code_string).loc\n        return {\"complexity\": complexity, \"maintainability\": round(float(maintainability), 2), \"loc\": loc}\n    except Exception:\n        return {\"complexity\": None, \"maintainability\": None, \"loc\": None}\n\ndef generate_code(model, tokenizer, prompt):\n    \"\"\"Generates code from a model, times the process, and cleans the output.\"\"\"\n    model_path = model.name_or_path.lower()\n    \n    # Apply model-specific prompt formatting\n    if \"gemma\" in model_path:\n        formatted_prompt = f\"<start_of_turn>user\\n{prompt}<end_of_turn>\\n<start_of_turn>model\\n\"\n    elif \"phi-2\" in model_path:\n        formatted_prompt = f\"Instruct: {prompt}\\nOutput:\"\n    elif \"stable\" in model_path:\n        formatted_prompt = f'\"\"\"\\n{prompt}\\n\"\"\"\\n'\n    else: # Default instruction format\n        formatted_prompt = f\"### Instruction:\\n{prompt}\\n\\n### Response:\"\n        \n    if tokenizer.pad_token is None:\n        tokenizer.pad_token = tokenizer.eos_token\n\n    # Tokenize the prompt and move it to the correct device (GPU/CPU)\n    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\", return_attention_mask=True).to(device)\n    \n    # Generate code and time the inference\n    start_time = time.time()\n    output_ids = model.generate(\n        inputs.input_ids, \n        attention_mask=inputs.attention_mask, \n        max_new_tokens=512, \n        temperature=0.1, # Low temperature for more deterministic, less creative output\n        do_sample=True, \n        pad_token_id=tokenizer.pad_token_id\n    )\n    end_time = time.time()\n\n    # Decode the generated token IDs back to a string\n    raw_output = tokenizer.batch_decode(output_ids)[0]\n    # Clean the raw output to get just the code\n    cleaned_code = clean_generated_code(raw_output, model_path)\n\n    return {\"code\": cleaned_code, \"gen_time\": end_time - start_time}\n\nprint(\"Backend engine with advanced metrics is ready.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T18:08:13.488767Z","iopub.execute_input":"2025-10-16T18:08:13.488990Z","iopub.status.idle":"2025-10-16T18:08:13.580981Z","shell.execute_reply.started":"2025-10-16T18:08:13.488972Z","shell.execute_reply":"2025-10-16T18:08:13.580167Z"}},"outputs":[{"name":"stdout","text":"Backend engine with advanced metrics is ready.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### 4. Pre-loading Models\n\nLoading a large language model into memory can be time-consuming. To make the interactive UIs feel responsive, this cell pre-loads all the models and their corresponding tokenizers defined in `MODELS_TO_TEST`. They are stored in a dictionary (`loaded_models`) for quick access later. Using `torch_dtype=torch.bfloat16` and `device_map=\"auto\"` helps optimize memory usage and automatically places the model on the available GPU.","metadata":{}},{"cell_type":"code","source":"# --- Section 4: Pre-Loading All Models ---\nloaded_models = {}\nprint(\"Starting to pre-load all models...\")\n\n# Iterate through the dictionary of models to test\nfor model_name, model_path in MODELS_TO_TEST.items():\n    if model_name not in loaded_models.keys():\n        print(f\"\\n--- Loading {model_name}... ---\")\n        try:\n            # Load the tokenizer\n            tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n            # Load the model with optimizations for memory and device placement\n            model = AutoModelForCausalLM.from_pretrained(\n                model_path, \n                torch_dtype=torch.bfloat16, # Use bfloat16 for reduced memory footprint\n                device_map=\"auto\", # Automatically map model layers to available devices (GPU/CPU)\n                trust_remote_code=True\n            )\n            # Store the loaded model and tokenizer\n            loaded_models[model_name] = {\"model\": model, \"tokenizer\": tokenizer}\n            print(f\"âœ… {model_name} loaded successfully.\")\n        except Exception as e:\n            print(f\"âœ— FAILED to load {model_name}. Error: {e}\")\n\nprint(\"\\n\" + \"=\"*50 + \"\\nAll available models are pre-loaded.\\n\" + \"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T18:08:13.581911Z","iopub.execute_input":"2025-10-16T18:08:13.582255Z","iopub.status.idle":"2025-10-16T18:10:51.307220Z","shell.execute_reply.started":"2025-10-16T18:08:13.582228Z","shell.execute_reply":"2025-10-16T18:10:51.306329Z"}},"outputs":[{"name":"stdout","text":"Starting to pre-load all models...\n\n--- Loading DeepSeek-Coder-1.3B... ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a7c5928907e4eef87555e8088b85333"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee6b5d04c2294e0da4ad0e027f82b0ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/631 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f58dd1814b14417b0e792671f0fa5c6"}},"metadata":{}},{"name":"stderr","text":"2025-10-16 18:08:21.592568: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760638101.839247      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760638101.902855      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.69G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5982168fc324c1f960326737353d48b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b382c2a5befc48b7922f446e6428c002"}},"metadata":{}},{"name":"stdout","text":"âœ… DeepSeek-Coder-1.3B loaded successfully.\n\n--- Loading Phi-2-2.7B... ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8169eb60dd74d7b95d2280c6b017ae8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b4e6f5365f64599a90400363875dd5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f83a5e0ddb84110a1fd949663ddd76b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91d84e0fb5c6471ebe3566c7f301224b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d65a7e98a934697bd00d4ab7d0a7b7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b265b99493d4c66ae40fe3e456096b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eaa310a1abf74253aeef96ee8907f0ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1e0dceca94c47909d7c11c93a938287"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79ca6d0e690f49d2ae0b23402251aabe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8553a9f3f17c475aba8f0c457a98b39c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4548e398ab1e423c9510639b54414ba4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a6c49a0eb0e4474b6f677c57d9919b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef7dcf0528f74e9395234dfd33c9954d"}},"metadata":{}},{"name":"stdout","text":"âœ… Phi-2-2.7B loaded successfully.\n\n--- Loading Gemma-2B-IT... ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/34.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6353e7d3bf9045caa66ef610eaf87c69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad3516c7fbbc4c5f8f1288e594ff340a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"489ef246849844fbb3a36692ec2308f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afba83e7ab694c50a3420f6f8fc23eb2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c910181681c94e6d8c3477ec6f883514"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3ab58bdcd674fdcaa61be8efa68c448"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fee0a80923014c0f97f0d14f82b6d5e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d261b5e483904fa2932e455b97c31b24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"281518a8e898483b92cc5621c7a901fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b828b15841644c085f48a28fec70b0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46893d4acab841d2bdf9deb997c5812e"}},"metadata":{}},{"name":"stdout","text":"âœ… Gemma-2B-IT loaded successfully.\n\n--- Loading Stable-code-3b... ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea83e796980d468b9dc6620e131ac0e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f3505156dfd4514ab929ad5c364c2f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46104c0b922643a8bff04c88b900d157"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/602 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4d45590459948be9de5e6297fcee6b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"913808eb372c4240b597c9737ea8de08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12e9b95076ea4d98a270bec0bfb858b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/610M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60ad6559da134225850e9bc6e70a11cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c47399111e3402a92da4ee03b039d19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"961fa3d5bb2a476b97349283769f3598"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0271ede457d34d28bb839a840ade08d2"}},"metadata":{}},{"name":"stdout","text":"âœ… Stable-code-3b loaded successfully.\n\n==================================================\nAll available models are pre-loaded.\n==================================================\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Verify which models have been loaded by checking the dictionary keys\nloaded_models.keys()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T18:10:51.308399Z","iopub.execute_input":"2025-10-16T18:10:51.309342Z","iopub.status.idle":"2025-10-16T18:10:51.313582Z","shell.execute_reply.started":"2025-10-16T18:10:51.309319Z","shell.execute_reply":"2025-10-16T18:10:51.312974Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"dict_keys(['DeepSeek-Coder-1.3B', 'Phi-2-2.7B', 'Gemma-2B-IT', 'Stable-code-3b'])"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"This cell shows an attempt to load an additional model (`replit-code-v1-3b`). The output shows that it failed, which is useful for demonstrating that not all models are compatible with the current setup","metadata":{}},{"cell_type":"markdown","source":"### 5. Interactive UI #1: Benchmark All Models\n\nThis section builds the first user interface using `ipywidgets`. It provides a simple way to test a single prompt across all the pre-loaded models simultaneously.\n\n1.  **UI Elements**: A text area for the user's prompt and a button to trigger the generation.\n2.  **Button Logic**: The `on_benchmark_all_clicked` function is attached to the button. When clicked, it takes the prompt, iterates through all models, calls the `generate_code` function for each, calculates metrics, and displays the results neatly in a table (Pandas DataFrame).","metadata":{}},{"cell_type":"code","source":"# Create the text input area for the prompt\nprompt_input_1 = widgets.Textarea(\n    placeholder=\"Enter your code prompt here (e.g., 'a function to calculate the factorial of a number')\",\n    layout={'width': '90%', 'height': '100px'}\n)\n\n# Create the button to start the benchmark\ngenerate_button_1 = widgets.Button(description=\"Generate & Benchmark All\")\n\n# Create an output area to display results\noutput_1 = widgets.Output()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T18:10:51.314190Z","iopub.execute_input":"2025-10-16T18:10:51.314380Z","iopub.status.idle":"2025-10-16T18:10:54.601723Z","shell.execute_reply.started":"2025-10-16T18:10:51.314364Z","shell.execute_reply":"2025-10-16T18:10:54.600882Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from IPython.display import clear_output\n\n# Define the function that runs when the 'Generate & Benchmark All' button is clicked\ndef on_benchmark_all_clicked(b):\n    with output_1:\n        clear_output() # Clear previous results\n        prompt = prompt_input_1.value\n        if not prompt:\n            print(\"Please enter a prompt.\")\n            return\n\n        print(f\"ðŸš€ Starting benchmark for prompt: '{prompt}'\\n\" + \"=\"*50)\n        results_this_run = []\n        # Loop through each pre-loaded model\n        for name, model_id in MODELS_TO_TEST.items():\n            print(f\"\\n--- Generating with {name} ---\")\n            # Generate code using the model's components\n            generated_code = generate_code(loaded_models[name]['model'],loaded_models[name]['tokenizer'], prompt)\n            # Calculate quality metrics for the generated code\n            metrics = calculate_advanced_metrics(generated_code['code'])\n            # Combine all results into a single dictionary entry\n            entry = {'Model': name, 'Prompt':prompt, **generated_code, **metrics}\n            results_this_run.append(entry)\n            \n        # Convert the list of results into a Pandas DataFrame for nice formatting\n        results_df = pd.DataFrame(results_this_run).round(2)\n        # Display the DataFrame as an HTML table\n        display(HTML(results_df.to_html().replace('\\\\n','<br>')))\n\n# Attach the function to the button's click event\ngenerate_button_1.on_click(on_benchmark_all_clicked)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T18:10:54.602426Z","iopub.execute_input":"2025-10-16T18:10:54.602750Z","iopub.status.idle":"2025-10-16T18:10:55.551903Z","shell.execute_reply.started":"2025-10-16T18:10:54.602717Z","shell.execute_reply":"2025-10-16T18:10:55.550309Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Display the UI components together\nprint(\"UI #1: Benchmark All Models\")\ndisplay(widgets.VBox([prompt_input_1, generate_button_1, output_1]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T18:10:55.552687Z","iopub.execute_input":"2025-10-16T18:10:55.553236Z","iopub.status.idle":"2025-10-16T18:10:56.578459Z","shell.execute_reply.started":"2025-10-16T18:10:55.553205Z","shell.execute_reply":"2025-10-16T18:10:56.577574Z"}},"outputs":[{"name":"stdout","text":"UI #1: Benchmark All Models\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Textarea(value='', layout=Layout(height='100px', width='90%'), placeholder=\"Enter your code proâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a39a70c7738438c8aa4833bec356672"}},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"### 6. Interactive UI #2: Inspect Selected Models\n\nThis section builds a second, more flexible UI. Instead of running on all models, the user can select specific models to compare using checkboxes. This is useful for focusing the analysis on a subset of models that seem promising.\n\nThe structure is similar to the first UI, with `ipywidgets` for the prompt, checkboxes, a button, and an output area. The `on_run_selected_clicked` function gathers input only from the checked models before running the generation and analysis.","metadata":{}},{"cell_type":"code","source":"# --- Section 6: UI #2 - Run on Selected Models ---\nprint(\"\\n\\n--- UI #2: Inspect Selected Models ---\")\n\n# Define the UI widgets\nprompt_input_selected = widgets.Textarea(placeholder='Enter a prompt for selected models...', layout={'width': '95%'})\nrun_selected_button = widgets.Button(description='Run Selected', button_style='success', icon='play')\noutput_selected = widgets.Output(layout={'border': '1px solid black', 'padding': '10px', 'overflow': 'scroll'})\n\n# Create a checkbox for each loaded model\nmodel_checkboxes = {name: widgets.Checkbox(value=True, description=name) for name in loaded_models.keys()}\ncheckbox_container = widgets.VBox(list(model_checkboxes.values()))\n\n# Define the function that runs when the 'Run Selected' button is clicked\ndef on_run_selected_clicked(b):\n    with output_selected:\n        output_selected.clear_output(wait=True)\n        prompt = prompt_input_selected.value\n        if not prompt: print(\"Please enter a prompt.\"); return\n\n        # Get the list of models that have been checked by the user\n        models_to_run = [name for name, cb in model_checkboxes.items() if cb.value]\n        if not models_to_run: print(\"Please select at least one model.\"); return\n\n        print(f\"Running prompt on {len(models_to_run)} selected models...\")\n        results_this_run = []\n        # Loop only through the selected models\n        for model_name in models_to_run:\n            print(f\"  - Generating with {model_name}...\")\n            components = loaded_models[model_name]\n            result = generate_code(components['model'], components['tokenizer'], prompt)\n            metrics = calculate_advanced_metrics(result['code'])\n\n            entry = {'Model': model_name, 'Prompt': prompt, **result, **metrics}\n            results_this_run.append(entry)\n\n        print(\"\\n--- Selected Run Complete ---\")\n        results_df = pd.DataFrame(results_this_run).round(2)\n        display(HTML(results_df.to_html().replace('\\\\n', '<br>')))\n\n# Attach the function to the button's click event\nrun_selected_button.on_click(on_run_selected_clicked)\n\n# Assemble and display the UI\nui_selected_models = widgets.VBox([prompt_input_selected, widgets.HTML(\"<h4>Select models to run:</h4>\"), checkbox_container, run_selected_button, output_selected])\ndisplay(ui_selected_models)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T18:10:56.580477Z","iopub.execute_input":"2025-10-16T18:10:56.580794Z","iopub.status.idle":"2025-10-16T18:10:57.515991Z","shell.execute_reply.started":"2025-10-16T18:10:56.580771Z","shell.execute_reply":"2025-10-16T18:10:57.515362Z"}},"outputs":[{"name":"stdout","text":"\n\n--- UI #2: Inspect Selected Models ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Textarea(value='', layout=Layout(width='95%'), placeholder='Enter a prompt for selected models.â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6940dce1291e443b8d12b1cf4f037f07"}},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"### 7. Automated Testing and Visualization\n\nThis final section automates the entire evaluation process to provide a high-level, objective comparison of the models. It runs a predefined list of 16 common coding prompts against every model.\n\nAfter collecting data for all prompts and models, it aggregates the results and generates four bar plots using `matplotlib` and `seaborn` to visualize the average performance of each model across several key metrics:\n- **Cyclomatic Complexity**: How complex is the generated code? (Lower is better)\n- **Maintainability Index**: How easy is the code to maintain? (Higher is better)\n- **Lines of Code (LOC)**: How verbose is the code? (Context-dependent, but often lower is better)\n- **Generation Time**: How fast is the model? (Lower is better) (Context-dependent)\n- **Lines of Code generated per sec**: How fast is the model? (Better for comparing models, due to same units regarding each prompt)(Context Independent)\n\nThis provides a comprehensive, at-a-glance summary of each model's strengths and weaknesses.","metadata":{}},{"cell_type":"code","source":"# A list of standard prompts to test the models against automatically\nTEST_PROMPTS = [\n    \"Write a Python function is_palindrome(s) that returns True if a string is a palindrome, ignoring case and non-alphanumeric characters.\",\n    \"Write a Python function find_common_elements(list1, list2) that returns a new list containing elements that are present in both input lists.\",\n    \"Implement a Stack class in Python with push, pop, peek, and is_empty methods.\",\n    \"Write a Python function get_unique_even_numbers(numbers) that takes a list of integers and returns a sorted list of unique even numbers, using a list comprehension.\",\n    \"Write a Python function merge_dictionaries(d1, d2) that merges two dictionaries. If a key exists in both, the value from the second dictionary should overwrite the first.\",\n    \"Write a Python function count_words_in_file(filepath) that reads a text file and returns the total number of words.\",\n    \"Write a Python function get_bitcoin_price() that uses the requests library to fetch the current Bitcoin price from the CoinDesk API (https://api.coindesk.com/v1/bpi/currentprice.json) and returns the price in USD as a float.\",\n    \"A function that takes a list of numbers and returns the sum.\",\n    \"Implement a binary search algorithm.\",\n    \"A function to find the factorial of a number using recursion.\",\n    \"Write a simple Flask route that returns 'Hello, World!'.\",\n    \"A function to parse a date string 'YYYY-MM-DD' and return a datetime object.\",\n    \"A Python class for a 'Car' with 'make', 'model', and 'year' attributes.\",\n    \"A function to read a CSV file using pandas and return a DataFrame.\",\n    \"A function to write a dictionary to a JSON file.\",\n    \"A function that uses regex to validate an email address.\"\n]\n\n# Define UI widgets for the automated test section\nresults = []\noutput_3 = widgets.Output()\n\n\n# Define what happens when the button is clicked\ndef download_csv(b):\n    clear_output(wait=True)\n    print(\"âœ… CSV file created successfully!\")\n    display(FileLink(csv_path, result_html_prefix=\"Click to download: \"))\n    \n# Define the main function for automated testing and plotting\ndef run_tests():\n    global results\n    results = [] # Reset results for a new run\n        # clear_output()\n    print(\"Starting automated testing across all prompts and models...\")\n\n    # Outer loop: iterate through each test prompt\n    for i, prompt in enumerate(TEST_PROMPTS):\n        print(f\"\\nRunning Prompt {i+1}/{len(TEST_PROMPTS)}: '{prompt}'\")\n        # Inner loop: iterate through each model\n        for name, model_id in MODELS_TO_TEST.items():\n            print(f\"  - Generating with {name}...\")\n            output_gen_code = generate_code(loaded_models[name]['model'],loaded_models[name]['tokenizer'], prompt)\n            code = output_gen_code['code']\n            gen_time = output_gen_code['gen_time']\n            # print('generation time is : ', gen_time)\n            metrics = calculate_advanced_metrics(code)\n            # Only append results if metrics could be calculated (i.e., code was valid)\n            if \"error\" not in metrics and metrics['complexity'] is not None:\n                results.append({\n                    \"prompt\": prompt,\n                    \"model\": name,\n                    \"generation_time\": gen_time,\n                    **metrics\n                })\n    \n    print(\"\\nâœ… Automated testing complete.\")\n    df = pd.DataFrame(results)\n    df['loc_per_sec']= df['loc']/df['generation_time']\n    if df.empty:\n        print(\"No results to plot.\")\n        return\n    \n\n            # --- CSV Download Button ---\n\n    # Save the DataFrame to a CSV file\n    csv_path = \"/tmp/model_test_results.csv\"\n    df.to_csv(csv_path, index=False)\n\n    # Create a download button\n    download_button = widgets.Button(\n        description=\"ðŸ“¥ Download Results as CSV\",\n        button_style='success',\n        tooltip=\"Click to download the results CSV\"\n    )\n    download_button.on_click(download_csv)\n\n    # Display the button\n    display(download_button)\n    return df\n\nresults_df = run_tests()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T18:10:57.516662Z","iopub.execute_input":"2025-10-16T18:10:57.516932Z","iopub.status.idle":"2025-10-16T18:22:10.949340Z","shell.execute_reply.started":"2025-10-16T18:10:57.516912Z","shell.execute_reply":"2025-10-16T18:22:10.948588Z"}},"outputs":[{"name":"stdout","text":"Starting automated testing across all prompts and models...\n\nRunning Prompt 1/16: 'Write a Python function is_palindrome(s) that returns True if a string is a palindrome, ignoring case and non-alphanumeric characters.'\n  - Generating with DeepSeek-Coder-1.3B...\n  - Generating with Phi-2-2.7B...\n  - Generating with Gemma-2B-IT...\n  - Generating with Stable-code-3b...\n\nRunning Prompt 2/16: 'Write a Python function find_common_elements(list1, list2) that returns a new list containing elements that are present in both input lists.'\n  - Generating with DeepSeek-Coder-1.3B...\n  - Generating with Phi-2-2.7B...\n  - Generating with Gemma-2B-IT...\n  - Generating with Stable-code-3b...\n\nRunning Prompt 3/16: 'Implement a Stack class in Python with push, pop, peek, and is_empty methods.'\n  - Generating with DeepSeek-Coder-1.3B...\n  - Generating with Phi-2-2.7B...\n  - Generating with Gemma-2B-IT...\n  - Generating with Stable-code-3b...\n\nRunning Prompt 4/16: 'Write a Python function get_unique_even_numbers(numbers) that takes a list of integers and returns a sorted list of unique even numbers, using a list comprehension.'\n  - Generating with DeepSeek-Coder-1.3B...\n  - Generating with Phi-2-2.7B...\n  - Generating with Gemma-2B-IT...\n  - Generating with Stable-code-3b...\n\nRunning Prompt 5/16: 'Write a Python function merge_dictionaries(d1, d2) that merges two dictionaries. If a key exists in both, the value from the second dictionary should overwrite the first.'\n  - Generating with DeepSeek-Coder-1.3B...\n  - Generating with Phi-2-2.7B...\n  - Generating with Gemma-2B-IT...\n  - Generating with Stable-code-3b...\n\nRunning Prompt 6/16: 'Write a Python function count_words_in_file(filepath) that reads a text file and returns the total number of words.'\n  - Generating with DeepSeek-Coder-1.3B...\n  - Generating with Phi-2-2.7B...\n  - Generating with Gemma-2B-IT...\n  - Generating with Stable-code-3b...\n\nRunning Prompt 7/16: 'Write a Python function get_bitcoin_price() that uses the requests library to fetch the current Bitcoin price from the CoinDesk API (https://api.coindesk.com/v1/bpi/currentprice.json) and returns the price in USD as a float.'\n  - Generating with DeepSeek-Coder-1.3B...\n  - Generating with Phi-2-2.7B...\n  - Generating with Gemma-2B-IT...\n  - Generating with Stable-code-3b...\n\nRunning Prompt 8/16: 'A function that takes a list of numbers and returns the sum.'\n  - Generating with DeepSeek-Coder-1.3B...\n  - Generating with Phi-2-2.7B...\n  - Generating with Gemma-2B-IT...\n  - Generating with Stable-code-3b...\n\nRunning Prompt 9/16: 'Implement a binary search algorithm.'\n  - Generating with DeepSeek-Coder-1.3B...\n  - Generating with Phi-2-2.7B...\n  - Generating with Gemma-2B-IT...\n  - Generating with Stable-code-3b...\n\nRunning Prompt 10/16: 'A function to find the factorial of a number using recursion.'\n  - Generating with DeepSeek-Coder-1.3B...\n  - Generating with Phi-2-2.7B...\n  - Generating with Gemma-2B-IT...\n  - Generating with Stable-code-3b...\n\nRunning Prompt 11/16: 'Write a simple Flask route that returns 'Hello, World!'.'\n  - Generating with DeepSeek-Coder-1.3B...\n  - Generating with Phi-2-2.7B...\n  - Generating with Gemma-2B-IT...\n  - Generating with Stable-code-3b...\n\nRunning Prompt 12/16: 'A function to parse a date string 'YYYY-MM-DD' and return a datetime object.'\n  - Generating with DeepSeek-Coder-1.3B...\n  - Generating with Phi-2-2.7B...\n  - Generating with Gemma-2B-IT...\n  - Generating with Stable-code-3b...\n\nRunning Prompt 13/16: 'A Python class for a 'Car' with 'make', 'model', and 'year' attributes.'\n  - Generating with DeepSeek-Coder-1.3B...\n  - Generating with Phi-2-2.7B...\n  - Generating with Gemma-2B-IT...\n  - Generating with Stable-code-3b...\n\nRunning Prompt 14/16: 'A function to read a CSV file using pandas and return a DataFrame.'\n  - Generating with DeepSeek-Coder-1.3B...\n  - Generating with Phi-2-2.7B...\n  - Generating with Gemma-2B-IT...\n  - Generating with Stable-code-3b...\n\nRunning Prompt 15/16: 'A function to write a dictionary to a JSON file.'\n  - Generating with DeepSeek-Coder-1.3B...\n  - Generating with Phi-2-2.7B...\n  - Generating with Gemma-2B-IT...\n  - Generating with Stable-code-3b...\n\nRunning Prompt 16/16: 'A function that uses regex to validate an email address.'\n  - Generating with DeepSeek-Coder-1.3B...\n  - Generating with Phi-2-2.7B...\n  - Generating with Gemma-2B-IT...\n  - Generating with Stable-code-3b...\n\nâœ… Automated testing complete.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Button(button_style='success', description='ðŸ“¥ Download Results as CSV', style=ButtonStyle(), tooltip='Click toâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0535e273244e46b082371adf3c8bd78c"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"results_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T18:22:10.950164Z","iopub.execute_input":"2025-10-16T18:22:10.950366Z","iopub.status.idle":"2025-10-16T18:22:10.979057Z","shell.execute_reply.started":"2025-10-16T18:22:10.950352Z","shell.execute_reply":"2025-10-16T18:22:10.978464Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                               prompt                model  \\\n0   Write a Python function is_palindrome(s) that ...  DeepSeek-Coder-1.3B   \n1   Write a Python function is_palindrome(s) that ...           Phi-2-2.7B   \n2   Write a Python function is_palindrome(s) that ...          Gemma-2B-IT   \n3   Write a Python function find_common_elements(l...  DeepSeek-Coder-1.3B   \n4   Write a Python function find_common_elements(l...           Phi-2-2.7B   \n5   Write a Python function find_common_elements(l...          Gemma-2B-IT   \n6   Implement a Stack class in Python with push, p...  DeepSeek-Coder-1.3B   \n7   Implement a Stack class in Python with push, p...           Phi-2-2.7B   \n8   Implement a Stack class in Python with push, p...          Gemma-2B-IT   \n9   Implement a Stack class in Python with push, p...       Stable-code-3b   \n10  Write a Python function get_unique_even_number...  DeepSeek-Coder-1.3B   \n11  Write a Python function get_unique_even_number...           Phi-2-2.7B   \n12  Write a Python function get_unique_even_number...          Gemma-2B-IT   \n13  Write a Python function merge_dictionaries(d1,...  DeepSeek-Coder-1.3B   \n14  Write a Python function merge_dictionaries(d1,...           Phi-2-2.7B   \n15  Write a Python function merge_dictionaries(d1,...          Gemma-2B-IT   \n16  Write a Python function count_words_in_file(fi...  DeepSeek-Coder-1.3B   \n17  Write a Python function count_words_in_file(fi...           Phi-2-2.7B   \n18  Write a Python function count_words_in_file(fi...          Gemma-2B-IT   \n19  Write a Python function get_bitcoin_price() th...  DeepSeek-Coder-1.3B   \n20  Write a Python function get_bitcoin_price() th...           Phi-2-2.7B   \n21  Write a Python function get_bitcoin_price() th...          Gemma-2B-IT   \n22  Write a Python function get_bitcoin_price() th...       Stable-code-3b   \n23  A function that takes a list of numbers and re...  DeepSeek-Coder-1.3B   \n24  A function that takes a list of numbers and re...           Phi-2-2.7B   \n25  A function that takes a list of numbers and re...          Gemma-2B-IT   \n26               Implement a binary search algorithm.  DeepSeek-Coder-1.3B   \n27               Implement a binary search algorithm.           Phi-2-2.7B   \n28               Implement a binary search algorithm.          Gemma-2B-IT   \n29               Implement a binary search algorithm.       Stable-code-3b   \n30  A function to find the factorial of a number u...  DeepSeek-Coder-1.3B   \n31  A function to find the factorial of a number u...           Phi-2-2.7B   \n32  A function to find the factorial of a number u...          Gemma-2B-IT   \n33  A function to find the factorial of a number u...       Stable-code-3b   \n34  Write a simple Flask route that returns 'Hello...  DeepSeek-Coder-1.3B   \n35  Write a simple Flask route that returns 'Hello...           Phi-2-2.7B   \n36  Write a simple Flask route that returns 'Hello...          Gemma-2B-IT   \n37  Write a simple Flask route that returns 'Hello...       Stable-code-3b   \n38  A function to parse a date string 'YYYY-MM-DD'...  DeepSeek-Coder-1.3B   \n39  A function to parse a date string 'YYYY-MM-DD'...           Phi-2-2.7B   \n40  A function to parse a date string 'YYYY-MM-DD'...          Gemma-2B-IT   \n41  A Python class for a 'Car' with 'make', 'model...  DeepSeek-Coder-1.3B   \n42  A Python class for a 'Car' with 'make', 'model...           Phi-2-2.7B   \n43  A Python class for a 'Car' with 'make', 'model...          Gemma-2B-IT   \n44  A Python class for a 'Car' with 'make', 'model...       Stable-code-3b   \n45  A function to read a CSV file using pandas and...  DeepSeek-Coder-1.3B   \n46  A function to read a CSV file using pandas and...           Phi-2-2.7B   \n47  A function to read a CSV file using pandas and...          Gemma-2B-IT   \n48  A function to read a CSV file using pandas and...       Stable-code-3b   \n49   A function to write a dictionary to a JSON file.  DeepSeek-Coder-1.3B   \n50   A function to write a dictionary to a JSON file.           Phi-2-2.7B   \n51   A function to write a dictionary to a JSON file.          Gemma-2B-IT   \n52   A function to write a dictionary to a JSON file.       Stable-code-3b   \n53  A function that uses regex to validate an emai...  DeepSeek-Coder-1.3B   \n54  A function that uses regex to validate an emai...           Phi-2-2.7B   \n55  A function that uses regex to validate an emai...          Gemma-2B-IT   \n56  A function that uses regex to validate an emai...       Stable-code-3b   \n\n    generation_time  complexity  maintainability  loc  loc_per_sec  \n0          9.464993           3            79.01    3     0.316957  \n1          4.526302           3           100.00    6     1.325585  \n2         12.950845           3            76.14   17     1.312656  \n3          7.598845           3            88.29    2     0.263198  \n4          4.140416           3            77.88    6     1.449130  \n5         14.465382           4            84.16   25     1.728264  \n6         10.855595           9            62.00   20     1.842368  \n7          8.555139           9            64.60   17     1.987110  \n8         14.474450           9            88.66   41     2.832577  \n9          6.871195           7            63.84   26     3.783912  \n10         9.725815           3            84.69    2     0.205638  \n11         1.972052           3            84.69    2     1.014172  \n12         5.096387           3            76.99   18     3.531914  \n13        10.055462           1           100.00    2     0.198897  \n14         2.615330           1           100.00    4     1.529443  \n15        13.109296           3            88.06   26     1.983325  \n16         5.935344           1           100.00    4     0.673929  \n17         3.683827           1           100.00    5     1.357284  \n18        12.862044           1           100.00   28     2.176948  \n19         7.681133           1           100.00    7     0.911324  \n20         4.228507           1           100.00    6     1.418941  \n21        11.119131           2            96.10   22     1.978572  \n22         4.359868           1           100.00   10     2.293647  \n23         3.789284           1           100.00    2     0.527804  \n24         2.300048           2            79.74    5     2.173867  \n25        13.554287           1           100.00   21     1.549325  \n26        14.968002           4            85.72   35     2.338321  \n27         7.712937           4            61.73   12     1.555827  \n28        18.690278           4            61.04   16     0.856060  \n29        14.561158          15            53.60   36     2.472331  \n30         6.135270           2            74.66    5     0.814960  \n31         2.921314           3            72.46    5     1.711558  \n32        11.795069           3            78.92   22     1.865186  \n33         3.089487           2            72.94    7     2.265748  \n34         9.878668           1            76.55    9     0.911054  \n35        24.866302           1           100.00    3     0.120645  \n36        10.517725           1            76.55   10     0.950776  \n37         2.756830           1            76.55   10     3.627355  \n38        10.827249           1           100.00    4     0.369438  \n39         2.639786           1           100.00    3     1.136456  \n40        13.569582           2           100.00   18     1.326496  \n41        10.060189           4           100.00    8     0.795214  \n42         3.200190           3           100.00    5     1.562407  \n43        16.379336           9           100.00   40     2.442101  \n44        23.412878           8            60.61   35     1.494904  \n45         4.952943           1           100.00    5     1.009501  \n46         2.403798           1           100.00    4     1.664034  \n47        12.301110           1           100.00   17     1.381989  \n48         4.610640           1           100.00    4     0.867558  \n49         8.600700           1           100.00    5     0.581348  \n50         2.956589           1           100.00    4     1.352911  \n51        14.098884           1           100.00   20     1.418552  \n52         4.523637           1           100.00    6     1.326366  \n53        10.988244           2           100.00    8     0.728051  \n54         5.384636           2           100.00    7     1.299995  \n55        15.742577           1            97.09   31     1.969182  \n56         5.443384           1           100.00    5     0.918546  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>model</th>\n      <th>generation_time</th>\n      <th>complexity</th>\n      <th>maintainability</th>\n      <th>loc</th>\n      <th>loc_per_sec</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Write a Python function is_palindrome(s) that ...</td>\n      <td>DeepSeek-Coder-1.3B</td>\n      <td>9.464993</td>\n      <td>3</td>\n      <td>79.01</td>\n      <td>3</td>\n      <td>0.316957</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Write a Python function is_palindrome(s) that ...</td>\n      <td>Phi-2-2.7B</td>\n      <td>4.526302</td>\n      <td>3</td>\n      <td>100.00</td>\n      <td>6</td>\n      <td>1.325585</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Write a Python function is_palindrome(s) that ...</td>\n      <td>Gemma-2B-IT</td>\n      <td>12.950845</td>\n      <td>3</td>\n      <td>76.14</td>\n      <td>17</td>\n      <td>1.312656</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Write a Python function find_common_elements(l...</td>\n      <td>DeepSeek-Coder-1.3B</td>\n      <td>7.598845</td>\n      <td>3</td>\n      <td>88.29</td>\n      <td>2</td>\n      <td>0.263198</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Write a Python function find_common_elements(l...</td>\n      <td>Phi-2-2.7B</td>\n      <td>4.140416</td>\n      <td>3</td>\n      <td>77.88</td>\n      <td>6</td>\n      <td>1.449130</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Write a Python function find_common_elements(l...</td>\n      <td>Gemma-2B-IT</td>\n      <td>14.465382</td>\n      <td>4</td>\n      <td>84.16</td>\n      <td>25</td>\n      <td>1.728264</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Implement a Stack class in Python with push, p...</td>\n      <td>DeepSeek-Coder-1.3B</td>\n      <td>10.855595</td>\n      <td>9</td>\n      <td>62.00</td>\n      <td>20</td>\n      <td>1.842368</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Implement a Stack class in Python with push, p...</td>\n      <td>Phi-2-2.7B</td>\n      <td>8.555139</td>\n      <td>9</td>\n      <td>64.60</td>\n      <td>17</td>\n      <td>1.987110</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Implement a Stack class in Python with push, p...</td>\n      <td>Gemma-2B-IT</td>\n      <td>14.474450</td>\n      <td>9</td>\n      <td>88.66</td>\n      <td>41</td>\n      <td>2.832577</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Implement a Stack class in Python with push, p...</td>\n      <td>Stable-code-3b</td>\n      <td>6.871195</td>\n      <td>7</td>\n      <td>63.84</td>\n      <td>26</td>\n      <td>3.783912</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Write a Python function get_unique_even_number...</td>\n      <td>DeepSeek-Coder-1.3B</td>\n      <td>9.725815</td>\n      <td>3</td>\n      <td>84.69</td>\n      <td>2</td>\n      <td>0.205638</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Write a Python function get_unique_even_number...</td>\n      <td>Phi-2-2.7B</td>\n      <td>1.972052</td>\n      <td>3</td>\n      <td>84.69</td>\n      <td>2</td>\n      <td>1.014172</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Write a Python function get_unique_even_number...</td>\n      <td>Gemma-2B-IT</td>\n      <td>5.096387</td>\n      <td>3</td>\n      <td>76.99</td>\n      <td>18</td>\n      <td>3.531914</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Write a Python function merge_dictionaries(d1,...</td>\n      <td>DeepSeek-Coder-1.3B</td>\n      <td>10.055462</td>\n      <td>1</td>\n      <td>100.00</td>\n      <td>2</td>\n      <td>0.198897</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Write a Python function merge_dictionaries(d1,...</td>\n      <td>Phi-2-2.7B</td>\n      <td>2.615330</td>\n      <td>1</td>\n      <td>100.00</td>\n      <td>4</td>\n      <td>1.529443</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Write a Python function merge_dictionaries(d1,...</td>\n      <td>Gemma-2B-IT</td>\n      <td>13.109296</td>\n      <td>3</td>\n      <td>88.06</td>\n      <td>26</td>\n      <td>1.983325</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Write a Python function count_words_in_file(fi...</td>\n      <td>DeepSeek-Coder-1.3B</td>\n      <td>5.935344</td>\n      <td>1</td>\n      <td>100.00</td>\n      <td>4</td>\n      <td>0.673929</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Write a Python function count_words_in_file(fi...</td>\n      <td>Phi-2-2.7B</td>\n      <td>3.683827</td>\n      <td>1</td>\n      <td>100.00</td>\n      <td>5</td>\n      <td>1.357284</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Write a Python function count_words_in_file(fi...</td>\n      <td>Gemma-2B-IT</td>\n      <td>12.862044</td>\n      <td>1</td>\n      <td>100.00</td>\n      <td>28</td>\n      <td>2.176948</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Write a Python function get_bitcoin_price() th...</td>\n      <td>DeepSeek-Coder-1.3B</td>\n      <td>7.681133</td>\n      <td>1</td>\n      <td>100.00</td>\n      <td>7</td>\n      <td>0.911324</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Write a Python function get_bitcoin_price() th...</td>\n      <td>Phi-2-2.7B</td>\n      <td>4.228507</td>\n      <td>1</td>\n      <td>100.00</td>\n      <td>6</td>\n      <td>1.418941</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Write a Python function get_bitcoin_price() th...</td>\n      <td>Gemma-2B-IT</td>\n      <td>11.119131</td>\n      <td>2</td>\n      <td>96.10</td>\n      <td>22</td>\n      <td>1.978572</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Write a Python function get_bitcoin_price() th...</td>\n      <td>Stable-code-3b</td>\n      <td>4.359868</td>\n      <td>1</td>\n      <td>100.00</td>\n      <td>10</td>\n      <td>2.293647</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>A function that takes a list of numbers and re...</td>\n      <td>DeepSeek-Coder-1.3B</td>\n      <td>3.789284</td>\n      <td>1</td>\n      <td>100.00</td>\n      <td>2</td>\n      <td>0.527804</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>A function that takes a list of numbers and re...</td>\n      <td>Phi-2-2.7B</td>\n      <td>2.300048</td>\n      <td>2</td>\n      <td>79.74</td>\n      <td>5</td>\n      <td>2.173867</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>A function that takes a list of numbers and re...</td>\n      <td>Gemma-2B-IT</td>\n      <td>13.554287</td>\n      <td>1</td>\n      <td>100.00</td>\n      <td>21</td>\n      <td>1.549325</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Implement a binary search algorithm.</td>\n      <td>DeepSeek-Coder-1.3B</td>\n      <td>14.968002</td>\n      <td>4</td>\n      <td>85.72</td>\n      <td>35</td>\n      <td>2.338321</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Implement a binary search algorithm.</td>\n      <td>Phi-2-2.7B</td>\n      <td>7.712937</td>\n      <td>4</td>\n      <td>61.73</td>\n      <td>12</td>\n      <td>1.555827</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Implement a binary search algorithm.</td>\n      <td>Gemma-2B-IT</td>\n      <td>18.690278</td>\n      <td>4</td>\n      <td>61.04</td>\n      <td>16</td>\n      <td>0.856060</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Implement a binary search algorithm.</td>\n      <td>Stable-code-3b</td>\n      <td>14.561158</td>\n      <td>15</td>\n      <td>53.60</td>\n      <td>36</td>\n      <td>2.472331</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>A function to find the factorial of a number u...</td>\n      <td>DeepSeek-Coder-1.3B</td>\n      <td>6.135270</td>\n      <td>2</td>\n      <td>74.66</td>\n      <td>5</td>\n      <td>0.814960</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>A function to find the factorial of a number u...</td>\n      <td>Phi-2-2.7B</td>\n      <td>2.921314</td>\n      <td>3</td>\n      <td>72.46</td>\n      <td>5</td>\n      <td>1.711558</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>A function to find the factorial of a number u...</td>\n      <td>Gemma-2B-IT</td>\n      <td>11.795069</td>\n      <td>3</td>\n      <td>78.92</td>\n      <td>22</td>\n      <td>1.865186</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>A function to find the factorial of a number u...</td>\n      <td>Stable-code-3b</td>\n      <td>3.089487</td>\n      <td>2</td>\n      <td>72.94</td>\n      <td>7</td>\n      <td>2.265748</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Write a simple Flask route that returns 'Hello...</td>\n      <td>DeepSeek-Coder-1.3B</td>\n      <td>9.878668</td>\n      <td>1</td>\n      <td>76.55</td>\n      <td>9</td>\n      <td>0.911054</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Write a simple Flask route that returns 'Hello...</td>\n      <td>Phi-2-2.7B</td>\n      <td>24.866302</td>\n      <td>1</td>\n      <td>100.00</td>\n      <td>3</td>\n      <td>0.120645</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Write a simple Flask route that returns 'Hello...</td>\n      <td>Gemma-2B-IT</td>\n      <td>10.517725</td>\n      <td>1</td>\n      <td>76.55</td>\n      <td>10</td>\n      <td>0.950776</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Write a simple Flask route that returns 'Hello...</td>\n      <td>Stable-code-3b</td>\n      <td>2.756830</td>\n      <td>1</td>\n      <td>76.55</td>\n      <td>10</td>\n      <td>3.627355</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>A function to parse a date string 'YYYY-MM-DD'...</td>\n      <td>DeepSeek-Coder-1.3B</td>\n      <td>10.827249</td>\n      <td>1</td>\n      <td>100.00</td>\n      <td>4</td>\n      <td>0.369438</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>A function to parse a date string 'YYYY-MM-DD'...</td>\n      <td>Phi-2-2.7B</td>\n      <td>2.639786</td>\n      <td>1</td>\n      <td>100.00</td>\n      <td>3</td>\n      <td>1.136456</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>A function to parse a date string 'YYYY-MM-DD'...</td>\n      <td>Gemma-2B-IT</td>\n      <td>13.569582</td>\n      <td>2</td>\n      <td>100.00</td>\n      <td>18</td>\n      <td>1.326496</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>A Python class for a 'Car' with 'make', 'model...</td>\n      <td>DeepSeek-Coder-1.3B</td>\n      <td>10.060189</td>\n      <td>4</td>\n      <td>100.00</td>\n      <td>8</td>\n      <td>0.795214</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>A Python class for a 'Car' with 'make', 'model...</td>\n      <td>Phi-2-2.7B</td>\n      <td>3.200190</td>\n      <td>3</td>\n      <td>100.00</td>\n      <td>5</td>\n      <td>1.562407</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>A Python class for a 'Car' with 'make', 'model...</td>\n      <td>Gemma-2B-IT</td>\n      <td>16.379336</td>\n      <td>9</td>\n      <td>100.00</td>\n      <td>40</td>\n      <td>2.442101</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>A Python class for a 'Car' with 'make', 'model...</td>\n      <td>Stable-code-3b</td>\n      <td>23.412878</td>\n      <td>8</td>\n      <td>60.61</td>\n      <td>35</td>\n      <td>1.494904</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>A function to read a CSV file using pandas and...</td>\n      <td>DeepSeek-Coder-1.3B</td>\n      <td>4.952943</td>\n      <td>1</td>\n      <td>100.00</td>\n      <td>5</td>\n      <td>1.009501</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>A function to read a CSV file using pandas and...</td>\n      <td>Phi-2-2.7B</td>\n      <td>2.403798</td>\n      <td>1</td>\n      <td>100.00</td>\n      <td>4</td>\n      <td>1.664034</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>A function to read a CSV file using pandas and...</td>\n      <td>Gemma-2B-IT</td>\n      <td>12.301110</td>\n      <td>1</td>\n      <td>100.00</td>\n      <td>17</td>\n      <td>1.381989</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>A function to read a CSV file using pandas and...</td>\n      <td>Stable-code-3b</td>\n      <td>4.610640</td>\n      <td>1</td>\n      <td>100.00</td>\n      <td>4</td>\n      <td>0.867558</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>A function to write a dictionary to a JSON file.</td>\n      <td>DeepSeek-Coder-1.3B</td>\n      <td>8.600700</td>\n      <td>1</td>\n      <td>100.00</td>\n      <td>5</td>\n      <td>0.581348</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>A function to write a dictionary to a JSON file.</td>\n      <td>Phi-2-2.7B</td>\n      <td>2.956589</td>\n      <td>1</td>\n      <td>100.00</td>\n      <td>4</td>\n      <td>1.352911</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>A function to write a dictionary to a JSON file.</td>\n      <td>Gemma-2B-IT</td>\n      <td>14.098884</td>\n      <td>1</td>\n      <td>100.00</td>\n      <td>20</td>\n      <td>1.418552</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>A function to write a dictionary to a JSON file.</td>\n      <td>Stable-code-3b</td>\n      <td>4.523637</td>\n      <td>1</td>\n      <td>100.00</td>\n      <td>6</td>\n      <td>1.326366</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>A function that uses regex to validate an emai...</td>\n      <td>DeepSeek-Coder-1.3B</td>\n      <td>10.988244</td>\n      <td>2</td>\n      <td>100.00</td>\n      <td>8</td>\n      <td>0.728051</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>A function that uses regex to validate an emai...</td>\n      <td>Phi-2-2.7B</td>\n      <td>5.384636</td>\n      <td>2</td>\n      <td>100.00</td>\n      <td>7</td>\n      <td>1.299995</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>A function that uses regex to validate an emai...</td>\n      <td>Gemma-2B-IT</td>\n      <td>15.742577</td>\n      <td>1</td>\n      <td>97.09</td>\n      <td>31</td>\n      <td>1.969182</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>A function that uses regex to validate an emai...</td>\n      <td>Stable-code-3b</td>\n      <td>5.443384</td>\n      <td>1</td>\n      <td>100.00</td>\n      <td>5</td>\n      <td>0.918546</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"global df\ndf = results_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T18:22:10.979774Z","iopub.execute_input":"2025-10-16T18:22:10.980016Z","iopub.status.idle":"2025-10-16T18:22:10.983289Z","shell.execute_reply.started":"2025-10-16T18:22:10.979996Z","shell.execute_reply":"2025-10-16T18:22:10.982569Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def plot_data(b):\n    with output_3: \n        # --- Visualization ---\n        print(\"\\nðŸ“Š Generating performance plots...\")\n        fig, axes = plt.subplots(4, 1, figsize=(12, 24))\n        fig.suptitle('Model Performance Metrics Across All Prompts', fontsize=16)\n\n        # Plot 1: Average Cyclomatic Complexity (Lower is Better)\n        avg_complexity = df.groupby('model')['complexity'].mean().sort_values()\n        std_complexity = df.groupby('model')['complexity'].std().reindex(avg_complexity.index)\n        avg_complexity.plot(kind='bar', ax=axes[0], color='skyblue', yerr=std_complexity, capsize=4)\n        axes[0].set_title('Average Cyclomatic Complexity (Lower is Better)')\n        axes[0].set_ylabel('Avg. Complexity')\n        axes[0].tick_params(axis='x', rotation=45)\n\n        # Plot 2: Average Maintainability Index (Higher is Better)\n        avg_mi = df.groupby('model')['maintainability'].mean().sort_values(ascending=False)\n        std_mi = df.groupby('model')['maintainability'].std().reindex(avg_mi.index)\n        avg_mi.plot(kind='bar', ax=axes[1], color='lightgreen', yerr=std_mi, capsize=4)\n        axes[1].set_title('Average Maintainability Index (Higher is Better)')\n        axes[1].set_ylabel('Avg. MI')\n        axes[1].tick_params(axis='x', rotation=45)\n\n        # Plot 3: Average Lines of Code (LOC)\n        avg_loc = df.groupby('model')['loc'].mean().sort_values()\n        std_loc = df.groupby('model')['loc'].std().reindex(avg_loc.index)\n        avg_loc.plot(kind='bar', ax=axes[2], color='salmon', yerr=std_loc, capsize=4)\n        axes[2].set_title('Average Lines of Code (LOC)')\n        axes[2].set_ylabel('Avg. LOC')\n        axes[2].tick_params(axis='x', rotation=45)\n\n        # Plot 4: Average Generation Time (Lower is Better)\n        avg_time = df.groupby('model')['generation_time'].mean().sort_values()\n        std_time = df.groupby('model')['generation_time'].std().reindex(avg_time.index)\n        avg_time.plot(kind='bar', ax=axes[3], color='purple', yerr=std_time, capsize=4)\n        axes[3].set_title('Average Generation Time (Lower is Better)')\n        axes[3].set_ylabel('Avg. Time (seconds)')\n        axes[3].tick_params(axis='x', rotation=45)\n\n        # Plot 5: Average number of lines of code generated per sec\n        avg_time = df.groupby('model')['loc_per_sec'].mean().sort_values()\n        std_time = df.groupby('model')['loc_per_sec'].std().reindex(avg_time.index)\n        avg_time.plot(kind='bar', ax=axes[3], color='purple', yerr=std_time, capsize=4)\n        axes[3].set_title('Average number of lines of codes generated per second (higher is better)')\n        axes[3].set_ylabel('Avg. loc ( per seconds)')\n        axes[3].tick_params(axis='x', rotation=45)\n        plt.tight_layout(pad=3.0)\n        # plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to prevent title overlap\n        plt.show()\n\n\nrun_test_button = widgets.Button(description=\"Generate Plots\")\n\n# Link button to function\nrun_test_button.on_click(plot_data)\n\n# Display UI\nprint(\"\\n\\nAutomated Testing & Visualization\")\ndisplay(widgets.VBox([run_test_button, output_3]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-16T18:32:33.735517Z","iopub.execute_input":"2025-10-16T18:32:33.735815Z","iopub.status.idle":"2025-10-16T18:32:33.756946Z","shell.execute_reply.started":"2025-10-16T18:32:33.735795Z","shell.execute_reply":"2025-10-16T18:32:33.756112Z"}},"outputs":[{"name":"stdout","text":"\n\nAutomated Testing & Visualization\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Button(description='Generate Plots', style=ButtonStyle()), Output(outputs=({'name': 'stdout', 'â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"501836d4b5524f89b659b6881c724b00"}},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
